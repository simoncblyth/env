\documentclass[a4paper]{jpconf}
\usepackage{graphicx}
\begin{document}
\title{Opticks : GPU Optical Photon Simulation for Particle Physics using NVIDIA\textregistered\ OptiX\texttrademark}

\author{Simon C Blyth}

\address{HEP Lab, Department of Physics, National Taiwan University, Taipei, Taiwan.}

\ead{simon.c.blyth@gmail.com}

\begin{abstract}
Opticks is an open source project that integrates the NVIDIA OptiX 
GPU ray tracing engine with Geant4 toolkit based simulations.
Massive parallelism brings drastic performance improvements with  
optical photon simulation speedup expected to exceed 1000 times Geant4 
when using workstation GPUs. Optical photon simulation time becomes 
effectively zero compared to the rest of the simulation.
Optical photons from scintillation and Cherenkov processes
are allocated, generated and propagated entirely on the GPU, minimizing 
transfer overheads and allowing CPU memory usage to be restricted to
optical photons that hit photomultiplier tubes or other photon detectors.
Collecting hits into standard Geant4 hit collections then allows the 
rest of the simulation chain to proceed unmodified.
Optical physics processes of scattering, absorption, reemission and 
boundary processes are implemented as CUDA OptiX programs based on the Geant4
implementations. Wavelength dependent material and surface properties as well as  
inverse cumulative distribution functions for reemission are interleaved into 
GPU textures providing fast interpolated property lookup or wavelength generation.
Geometry is provided to OptiX in the form of CUDA programs that return bounding boxes 
for each primitive and single ray geometry intersection results. Some critical parts 
of the geometry such as photomultiplier tubes have been implemented analytically 
with the remainder being tesselated. 
OptiX handles the creation and application of a choice of acceleration structures
such as boundary volume heirarchies and the transparent use of multiple GPUs. 
OptiX supports interoperation with OpenGL and CUDA Thrust that has enabled 
unprecedented visualisations of photon propagations to be developed 
using OpenGL geometry shaders to provide interactive time scrubbing and    
CUDA Thrust photon indexing to provide interactive history selection. 
%Validation and performance results are shown for the photomultiplier based 
%Daya Bay and JUNO Neutrino detectors. 
\end{abstract}




%
% target audience should know the below, so dont bother
%
%Adoption of parallelism at various levels has become mandatory in order to 
%fully exploit the capabilities of current computing hardware.  
%CUDA is a parallel computing platform and application programming interface  
%introduced by NVIDIA in 2006. Subsequently hundreds of millions of CUDA enabled GPUs 
%in notebooks and workstations have been shipped driven mainly by consumer demand for
%fast 3D graphics is computer games. 
%
%
%
% hmm dont mention MIC, as I know very little about it
% In contrast the recently introduces Intel MIC processors target high end workstations only.  
%Intel proposes the use of many integrated core (MIC) architecture coprocessors.
%
% too breathless ... relax, not an elevator pitch
% BELOW CAN GO IN CONCLUSION, NOT INTRODUCTION
%
%Opticks works together with Geant4 replacing just the optical photon simulation with
%an equivalent GPU simulation based on the NVIDIA OptiX ray tracing engine.
%Opticks optical photon simulation uses ray tracing mega-kernels generated 
%by the NVIDIA OptiX domain optimized just-in-time compiler from CUDA implementations
%of optical scattering, absorption, boundary processes and scintillator reemission.
%
%Massive GPU parallelism and state-of-the-art SBVH\cite{sbvh} geometry intersection acceleration structures
%orchestrated with multi-level load balanced execution model using persistent threads 
%combine to yield drastic performance improvements with an optical photon simulation speedup 
%expected to exceed 1000 times Geant4 when using workstation GPUs. 
%Near linear performance scaling with GPU cores across multiple GPUs is observed. 
%In addition to removing the optical photon simulation bottleneck the CPU memory 
%constraints are also removed as only photons that hit detectors need to 
%consume CPU memory.
%
%Development of GPU ray tracing algorithms remains an active area of research, NVIDIA OptiX
%Direct application of hardware and software developed over the past 20 years 
%to feed the demands of the entertainment, gaming and design industries over the past 20 years 
%
  

\section{Introduction}

Newton's Opticks\cite{newton} first elucidated the optical physics 
that is central to the operation of a wide gamut of machines from medical imaging 
scanners to neutrino detectors. Drastically improved optical photon simulation 
performance can be transformative to the design, understanding 
and operation of such machines. Opticks\cite{opticksURL} enables Geant4\cite{g4A}\cite{g4B}\cite{g4C}
based simulations to benefit from the high performance GPU ray tracing made accessible
by NVIDIA\textregistered\ OptiX\texttrademark\ \cite{optixPaper}\cite{optixSite}.

%Photons in the visible range from 390-700 nm have such low energies 3.2-1.8 eV
%($E = hc/\lambda = 1240 eV.nm/\lambda$) that enormous numbers of photons 
%can be produced even by low energy processes. 

Cosmic muon induced processes are crucial backgrounds for neutrino
detectors such as Daya Bay~\cite{dyb} and JUNO\cite{juno}, 
necessitating the use of muon veto systems.
Minimizing the dead time and dead volume that results from applying 
a veto requires an understanding of the detector response to the muon.
Large simulated samples of muon events are crucial in order to 
develop such an understanding and also to provide efficiency estimates 
that are critical inputs to physics analyses.

The number of optical photons estimated to be produced by a muon of 
typical energy 100 GeV crossing the Daya Bay detector is at the level of several millions, 
for JUNO the estimate is an order of magnitude larger. 
Profiling the Geant4 toolkit based Daya Bay simulation 
shows the propagation of optical photons to consume more than 95\% of CPU time. 
In addition to the CPU time the memory requirements for handling many millions 
of photons pose severe constraints.  

%A detailed understanding of the generation and propagation of optical 
%photons is vital to the design, operation and analysis of photomultiplier
%based neutrino detectors 
%
%Opticks\cite{opticksURL} is an open source software package 
%that aims to solve the problem of optical photon simulation described below.
%Opticks works together with the Geant4\cite{g4A}\cite{g4B}\cite{g4C} toolkit, 
%replacing only the optical photon simulation with an 
%equivalent optical simulation implemented on the GPU and accelerated 
%by the NVIDIA OptiX\cite{optixSite}\cite{optixPaper} ray tracing engine.
%
%\begin{itemize}
%\item Optical Photon Simulation Problem
%\item Hybrid Solution
%\item Connection between Ray Traced Image Synth and Optical Photon Simulation
%\item external simulation cost : "context" duplication of geometry, materials, surfaces
%\item open source opticks\cite{opticksURL} \cite{newton}
%\item Opticks requirements, CUDA capability 3.0
%\end{itemize}


%A detailed understanding of the generation and propagation of optical 
%photons is vital to the design, operation and analysis of photomultiplier
%based neutrino detectors such as the Daya Bay~\cite{dyb} and JUNO\cite{juno} experiments. 

%A fundamental requirement of optical photon propagation is to compute 
%the next boundary intersection of a ray in the direction of travel 
%at each step of the propagation in a highly efficient manner.

%Geant4 uses a solid based geometry model with volumes of particular shape and material, 
%such as cylinders of acrylic, GdLS or water. These volumes form a tree of mother volumes 
%containing non-intersecting daughter volumes which in turn contain their own daughters, and so on. 
%The tree structure and containment condition limits the number of volumes which 
%must be be interrogated in order to compute the next boundary intersection, as if the 
%mother of a volume does not intersect then its daughters cannot.

%\subsection{Solution : Geant4 + GPU ray tracing}

As optical photons in neutrino detectors can be considered to be produced 
by only the scintillation and Cerenkov processes and yield only hits 
on photomultiplier tubes it is straightforward to integrate an
external optical photon simulation with a Geant4 simulation of all other particles.
%
The uncoupled, highly parallel and rather simple nature of the optical physics 
that is sufficient to describe neutrino detectors makes optical photon propagation 
well suited to general purpose GPU computing techniques where
high performance requires massive parallelism with minimal communication between threads
and low register usage\cite{megakernels}.  

The most computationally intensive aspect of optical photon simulation
is the determination, at each step of the propagation, of the intersection point 
of rays representing photon directions with the geometry of the detector. This 
is understandable as the large data structures that model the geometry contrast
markedly with the simple structures used to model the optical physics.

%Computer graphics algorithms for rendering predominantly uses rasterization,
%which projects 3d models of objects onto a 2d image plane and combines 
%the contributions into pixel values using a depth buffer structure. 

Image synthesis algorithms in computer graphics can be divided into 
the two approaches of rasterization and ray tracing. 
Ray tracing casts rays from a viewpoint through image plane pixels out 
into the scene and recursively reflects and refracts rays with the geometry intersected 
to compute pixel values. Rasterization projects 3d object vertices onto the image plane.
The closeness of the ray tracing algorithm to the optical physics of image formation
makes it the preferred approach for the creation of realistic images. 
Ray traced image synthesis and optical photon simulation have much in common, 
they are both limited by the calculation of intersections between rays and geometry.  
Due to the many applications of realistic image synthesis in the 
advertising, design, film and games industries the calculation of ray geometry intersections 
continues to be extensively optimized by the computer graphics community with performance claims 
reaching several hundreds of millions of intersections per second\cite{understanding}\cite{understandingAddendum}.


\section{Related Work}

\subsection{Chroma}

Chroma\cite{chromaURL}\cite{chromaB} implements both GPU ray tracing and optical photon simulation 
using CUDA kernels that are launched from python scripts. 
The development of Opticks was made possible by the experience gained from working with Chroma.
Ray tracing performance comparisons between OptiX and my 
fork of Chroma\cite{chromaFork} halted my work with Chroma.
In addition to performance other limitations of Chroma include:
no support for multiple GPUs, memory inefficient photon handling requiring the copying of photons from CPU to GPU
and memory inefficient geometry handling due to lack of geometry instancing.
Also the use of python makes integration with Geant4 and other C++ code inconvenient. 

\subsection{VecGeom and GeantV}

%http://geant.cern.ch/content/publications

The GeantV\cite{GeantV} (Geant-Vector) project aims 
to develop an all-particle transport simulation package that is 
several times faster than Geant4. The principal approach investigated 
is the application of SIMD operations across vectors of multiple tracks 
collected from multiple events according to locality criteria, requiring
development of vectorised geometry algorithms.  
The VecGeom\cite{VecGeom} project aims to provide these algorithms and also 
to optimize scalar performance; CUDA implementations are also provided.
%
%Currently Opticks implements its own CUDA/OptiX geometry algorithms
%for the small number of solids required to provide an analytic description 
%of Photomultiplier tubes. 

%\subsection{JUNO Fast Simulation}
%
%The implementation of a fast simulation of the JUNO central detector has 
%been studied in\cite{junoFastSim} using the voxel method. The core
%of the method is to build the connection between the visible energy
%in a voxel and the response of the photomultiplier tubes.
%Essentially the approach persists parameterized response distributions 
%of scintillation photons obtained from a full Geant4 simulation which 
%can be then sampled to form an approximation of the full simulation.
%Cerenkov photon anisotropy prevents application of this approach.
%The symmetry of the detector geometry greatly reduces the number of 
%response distributions that need to be persisted. Details such as 
%shadowing from support struts or other things that break the symmetry 
%require increases in numbers of parameter binning.  
%
%Fast simulation techniques do not provide an alternative to full simulation, 
%they merely provide an approximation of the full simulation which trade 
%simulation time with file input/output time and bookkeeping. 
%
% too much detail:
%For each bin of R-theta parameter space distributions of nPE and hit time
%are collected from a full simulation.
%
%\subsection{IceCube GPU Photon Propagation}
%
%IceCube\cite{IceCubeGPU} has used GPU photon tracking in production, replacing 
%a two-stage parameterized approach with full photon simulation. 
%



\section{NVIDIA\textregistered\ OptiX\texttrademark}

OptiX\cite{optixPaper} \cite{optixSite} is a general-purpose ray tracing engine 
designed for NVIDIA GPUs that exposes an accessible single ray programming model 
while still providing state of the art acceleration competitive with 
manually optimized approaches\cite{understanding}\cite{understandingAddendum}.  
%
The core principle of OptiX is a that ray tracing pipelines can be implemented 
from the combination of a small set of user provided operations
in a manner directly analogous to how OpenGL shaders combine to create rasterization pipelines.
These operations are provided to OptiX in the form of CUDA programs 
%\cite{cudaPaper} \cite{cudaURL} 
including: ray generation, object intersection and closest hit programs that operate on 
single rays. These programs together with a ray payload data structure are combined 
into a ray tracing kernel by a domain optimized Just-In-Time compiler.

Scene data is provided to OptiX via a high level node structure that 
Opticks constructs using the OptiX C++ API. 
Geometry leaf nodes are assigned primitive counts 
and associated CUDA programs that return bounding boxes and 
report ray primitive intersection positions. 
The programs access GPU geometry buffers which are copied from the CPU at initialization.
Multiple geometry instance nodes are allowed to share geometry objects, this 
together with the use of transform nodes is used to model many thousands of  
photomultiplier tubes without repetition of information. This so called geometry 
instancing drastically reduces the GPU memory needed to contain the scene data.

The central data structure enabling fast ray tracing is a geometry index
known as an acceleration structure which sorts a scene’s primitives 
into spatial or object groups. 
Heirarchical tree structures are typically used
with leaves representing the primitives.  Rejection of higher level
volumes allows all contained volumes to be removed from the intersection
search. OptiX provides a simple interface to associate acceleration structures 
with different parts of a scene geometry but all the details of creation, updating 
and traversal are handled by OptiX internally using the geometrical information provided by the 
bounding box program. Opticks currently uses the SBVH (Split boundary volume heirarchy) structure\cite{sbvh}.

The design of OptiX is informed by studies\cite{understanding}\cite{understandingAddendum}
comparing simulated GPU performance against measurements
for various ray tracing algorithms. The GPU simulators 
provide hard upper bounds based on the native assembly operations
for each algorithm, the SIMD width and work scheduling approach. 
OptiX uses a dynamically load balanced GPU execution model that enables
performance to scale linearly with CUDA cores across multiple GPUs. 

This scaling linearity has been verified by ray trace measurements on a 
borrowed 4 GPU workstation (Tesla K40m) by progressively masking GPUs.


\section{Geometry}

Implementing an equivalent external simulation demands that the Geant4 
context of geometry, material and surface properties is available on the GPU.
This is achieved by first writing the tesselated geometry into a COLLADA/DAE XML file  
%\cite{colladaURL} 
using the G4DAE\cite{g4daeURL} geometry exporter which was implemented based upon the 
standard GDML exporter. COLLADA is a widely supported 3D file format allowing G4DAE exported geometries 
to be visualized and imported into many commercial and open source tools.
All material and surface properties as a function of wavelength are 
included in the G4DAE using the extensibility of the file format.
Opticks reads the G4DAE geometry file using a forked version\cite{AssimpFork} of the
Assimp\cite{Assimp} asset importer that adds handling of the extra optical material and surface
properties. 
% GEOINSTANCING
The loaded volume tree is analysed to locate repeated geometry based 
on progeny transform digests and mesh indices, yielding geometry subtrees and transforms.
These allow OptiX and OpenGL geometry instancing to be used, which avoids repetition of geometry 
data on the GPU. Use of geometry instancing was found to be essential in order to fit the 
data into the GPU memory available. 
% GEOCACHE
To avoid repeated parsing of XML at every initialization
a geometry cache was implemented using the NPY\cite{NPY} serialization format, enabling 
initialization times for the JUNO geometry to be reduced from several minutes to several seconds.
% NPY
The NPY format, consisting simply of a header describing array type and dimension together 
with the serialized data buffer, is used for all Opticks serialization due
to the ease with which data can be directly uploaded to the GPU and also 
loaded into ipython\cite{ipython} as NumPy\cite{numpy} arrays for debugging and analysis.

% BOUNDARY BASED GEOMETRY MODEL
Optical physics and ray tracing favors the use of a boundary based geometry model 
rather than the tree of volumes model used by Geant4. 
At initialization the volume tree is translated into a boundary based model 
with each primitive labelled with a boundary index which uniquely identifies 
a combination of four indices representing outer and inner materials and outer and inner surfaces.
Outer/inner surfaces handle inwards/outwards going photons allowing the Geant4 border and skin 
surface functionality to be translated.
% TEX
GPUs contain hardware dedicated to fast texture lookup and interpolation. 
This is exploited by using a single 2d float4 texture named the boundary texture 
that contains interleaved material and surface properties as a function of wavelength. 
The two dimensions correspond to the wavelength of the photon and the inner/outer material/surface 
within a particular boundary. 
The boundary index returned from a ray traced primitive intersection together with 
an orientation offset identified by the sign of the dot product of geometric normal and ray direction 
enables up to four relevant wavelength interpolated material or surface properties to be 
obtained from a single hardware optimized texture lookup.
The material properties include refractive index, absorption length, scattering length, reemission probability and  group velocity
and surface properties include detection efficiency, absorption probability, specular and diffuse reflectivity.

%ANALYTIC VS TESSELATED
OptiX provides only the acceleration of geometrical intersection not the intersection itself. 
This allows use of any primitive shape for which bounding box and ray primitive intersections can be returned.
Use of tesselated geometry with triangle primitives allows all primitives to share the same intersection code. 
However to improve realism for the optically critical photomultiplier tubes 
an analytic description was developed based upon the original constructive solid geometry (CSG)
which defines solids using boolean set operations applied to basis shapes such as spheres and cylinders.
Implementation of general CSG boolean handling was avoided by partitioning the geometry at 
the intersection planes of the basis shapes to form primitives 
composed of slices of single basis shapes. The five solids representing the Daya Bay 
photomultiplier tube are partitioned into a total of twelve single primitive parts 
which are copied to the GPU instead of the close to 3000 triangles of the tesselated geometry. 


% HMM: HOW MUCH G4 COVERAGE ???  BETTER TO KEEP TO MINIMUM, MORE SPACE FOR OPTICKS
%
% Smart Voxels
% P. Kent, Pure Tracking and Geometry in Geant4,Geant4 internal note, April 1995.
%
% http://geant4.web.cern.ch/geant4/collaboration/working_groups/geometry/
% 
% http://geant4.cern.ch/results/papers/geometry-IEEE04.pdf
% The Geant4 Geometry Modeler G. Cosmo, CERN
% 
% A technique for optimised navigation in regulargeometriesPedro Arce, John Apostolakis and Gabriele Cosmo
% 
%\begin{itemize}
%\item Geometry model implications, 
%\item G4DAE Geometry Exporter, volume tree, use extensiblity of DAE to include material/surface props as function of wavelength
%\item importing Geometry, assimpfork \cite{Assimp} \cite{AssimpFork}
%\item surface based geometry (BREP) more natural for ray tracing 
%\item Geometry model translation, volume to surface based geometry (4 indices attached to primitives) in/out G4LogicalBorderSurface
%SKIP \item mesh fixing with OpenMesh\cite{OpenMesh}
%\item geocache using NumPy serialization
%\item geometry instancing mandatory
%\item analytic primitives for PMT, manual approach 
%\item material and surface properties in GPU textures
%\end{itemize}


\section{Event}

Opticks is integrated with Geant4 by modifications to the 
Geant4 scintillation and Cerenkov processes, instead of 
generating photons in a loop the parameters of the so called genstep 
are collected into a buffer. 
The parameters include the number of photons to generate and a line segment 
along which to generate them togther with other parameters used to the 
define the angular and wavelength distributions.
%
Collecting and copying gensteps rather than photons has the
advantage of greatly reducing transfer overheads and avoids the 
need to allocate memory twice.
In order to associate each photon with its genstep a seeding 
procedure is implemented using the CUDA Thrust\cite{thrust}\cite{thrustURL} 
library that distributes genstep indices to photons entirely on the GPU.

% CURAND
Opticks uses the cuRAND\cite{curandURL} library, which is part of the CUDA toolkit, 
%\cite{cudaPaper}\cite{cudaURL} 
for the concurrent generation of millions of reproducible sequences of pseudorandom numbers. Concurrent generation is handled by assigning 
sub-sequences to each thread which maintain their position within the sub-sequence. Initialization of cuRAND within the 
OptiX ray generation program was found to require increasing the stack size by a factor of 10 which led to 
poor ray tracing performance. To avoid this issue a cuRAND initialization was moved to a separate CUDA launch, allowing 
OptiX programs to use cuRAND without having to initialize it.

OptiX ray generation programs form the entry point to the ray tracing pipeline. 
A single OptiX launch conceptually creates an instanciation of the program for every photon. 
The generation of scintillation, Cerenkov or artificial torch photons 
are implemented in the ray generation program immediately prior to the propagation loop.
% that limits the number of ray trace operations for the photon. 
Within the loop a ray trace is performed that provides the distance to the closest boundary and its boundary index.
The boundary index together with the photon wavelength yields via texture lookups material properties 
such as absorption length, reemission probability and scattering length. 
These quantities together with uniform random number throws determine 
whether the photon is aborbed, scattered, undergoes reemission or survives to the boundary. 
Scintillator reemission changes the direction, polarization and wavelength of the photon. 
An inverted cumulative distribution function saved into a GPU texture allows reemission wavelengths 
to be generated from uniform random number texture lookups.

Photons reaching a boundary which has no associated optical surface are reflected or 
transmitted using a simplified translation of the Geant4 boundary processing 
with optimization techniques from the ray tracing literature that avoid the 
use of trancendental functions. Photons reaching a surface with an associated optical 
surface are detected, absorbed, diffusely reflected or specularly reflected following 
the Geant4 implementations. 

Keeping all photon operations on the GPU allows millions of optical photons 
to be generated and propagated with only the small fraction that are detected 
requiring memory allocation on the CPU to allow them to 
be copied back, using Thrust stream compaction.

%The implementation does not cover all the cases that Geant4 does.
%\begin{itemize}
%\item integrated Geant4/Opticks workflow
%\item cuRAND random numbers, initialization stack workaround
%\item generation of scintillation and Cerenkov photons from gensteps (explain: Geant4 process "stack")
%\item GPU resident photons, all operations done on GPU: seeded (assigned gensteps), generated, propagated, indexed 
%SKIP \item multi-event handling 
%\end{itemize}


\section{Visualisation}

\begin{figure}[htbp]
\centering
%\capstart

%http://tex.stackexchange.com/questions/12939/png-importing-it-with-latex-pdflatex-xelatex
%http://tex.stackexchange.com/questions/21627/image-from-includegraphics-showing-in-wrong-image-size
% Opening in Preview shows 640x360px 72px/inch 

%\includegraphics[natwidth=640bp,natheight=360bp,resolution=500]{jpmt-inside-wide_crop_half_half.png}
%\includegraphics[angle=45]{jpmt-inside-wide.png}
\includegraphics[resolution=100]{jpmt-inside-wide_crop_half_half.png}
\caption{Simulated Cerenkov and scintillations photons from a 100 GeV muon travelling
across the JUNO antineutrino detector viewed from inside the spherical scintillator.
Primary particles are simulated by Geant4, generation ``steps'' of the primaries
are transferred to the GPU and photons are generated, propagated and visualized
all on the GPU. Photons that hit PMTs
are returned back to Geant4 to be included into standard hit collections.
Photon colors indicate the polarization direction.}
\end{figure}






% NOTE: THE BELOW NEEDS VERIFICATION AND ALMOST CERTAINLY DEBUGGING : SO SKIP
%NVIDIA GPUs are not required for visualization.
%This capability is enabled by using a layered and ordered dependency 
%structure of the almost 20 C++ packages that make up Opticks. 

Opticks provides rasterized views of geometry using OpenGL 4+ shaders
and ray traced views using OptiX ray generation programs and provides 
a GUI implemented with ImGui\cite{ImGui}.
These views can be composited together using fragment depth information 
that is calculated and included with each ray traced pixel.
The OptiX ray generation program uses the same geometry intersection 
code as that used by the photon simulation program.  

Interoperation techniques enable buffer sharing between OpenGL and OptiX 
that allow buffers written by OptiX programs to be directly rasterized 
with GLSL shaders invoked by OpenGL draw commands. Such techniques 
have been used to interactively visualize propagations of up to 16 
steps of several millions of photons. Domain compression was used 
to squeeze the photon step parameters position, time, polarization 
and wavelength into 128 bits. 

OpenGL geometry shaders are used to provide interactive forward/backwards time scrubbing
and interactive photon history selection. Scrubbing uses the propagation time as an input 
allowing interpolation between the recorded photon positions.  
History selection relies on photon indexing implemented with CUDA Thrust accelerated 
sorting of 64 bit integers representing up to 16 steps of photon propagation history.   
History selection combined with artificial photon sources has proved 
very useful for debugging the simulation.

The GPU accelerated visualization performance has made it possible to create 
screen capture movies illustrating simulated event propagations 
within the detector geometry, that have proved useful for outreach to a wide public audience. 

%\begin{itemize}
%\item photon step sequence recording
%\item photon indexing with CUDA Thrust 
%SKIP: \item small number of VBOs for entire geometry, one for non-instanced, one for each case of instanced geometry
%SKIP: \item persistent viewpoint bookmarks 
%\item composited OpenGL rasterized render and OptiX ray trace, using Z-depth calulated for each raytrace pixel.
%\item OptiX/OpenGL/CUDA/Thrust interoperation, same GPU buffers shared
%\item OpenGL based visualization, geometry shaders time scrubbing 
%\item index enables interactive photon history selection
%\item GUI using ImGui\cite{ImGui}  % passing mention
%SKIP:\item layered dependencies, visualization on non-CUDA capable GPUs
%\item screenshot figures, one dyb one JUNO ? showing the GUI 
%\end{itemize}

\section{Validation}

%\begin{itemize}
%\item CFG4: one executable doing two simulations: pure G4 and G4+Opticks 
%\item G4 step recorder in Opticks event format
%\item simple test geometries, commandline configured 
%\item torch light source, commandline configured 
%SKIP, COVERED GENERALLY INSTEAD: \item fresnel, rainbow, PmtInBox, tconcentric
%SKIP COVERED IN VIZ:\item compressed recording of propagation steps
%\item frequency count chi2 distance, distrib chi2
%\end{itemize}

All of the optical photon propagation processes relevant to Daya Bay and JUNO
are implemented on the GPU within OptiX CUDA programs, based upon the Geant4 implementations. 
The processes include absorption, Rayleigh scattering, Fresnel reflection and refraction, diffuse reflection
and scintillator reemission. Similarly optical photon generation from scintillation and Cerenkov processes
using buffers of generation step parameters collected from Geant4
are implemented on the GPU within OptiX CUDA programs.

Validation comparisons use a single executable that performs both
the Geant4 and Opticks optical simulations and writes two events using
an Opticks event format that includes highly compressed information
for the first 16 photon propagation points.
These events are compared by forming $\chi^{2}$ distances for:

\begin{itemize}
\item photon history counts within the 100 most frequent categories
\item photon step point distributions of position, time, wavelength and polarization 
\end{itemize}

Opticks aims to achieve a match between pure Geant4 simulations and the hybrid 
Opticks/Geant4 simulation for full geometries. 
To facilitate validation Opticks supports dynamic test geometries and light sources
configured from the commandline that reuse materials and surfaces of a base geometry.
All relevant processes including scintillator reemission have been validated 
when using geometries that can be fully analytically described by Opticks. 
However, Opticks currently provides analytic CUDA intersection implementations 
for only a few geometrical shapes and does not yet support general boolean CSG geometries.  
This limitation complicates validation of full geometries as the tesselation 
approximation used for much of the geometry prevents precise photon history comparisons.


\section{Summary and Outlook}

Photon propagation timings for validated geometries 
obtained with a mobile Kepler generation GPU with only 384 CUDA cores are listed in Table 1.
A speedup factor of 200 between Opticks compute and Geant4 is apparent.
Ray trace performance has been verified to scale linearly with CUDA cores, thus 
GPU workstations with 10-20 more cores are expected by linear extrapolation 
to easily achieve speed up factors exceeding 1000.  
However once speedup factors exceed a level of perhaps 100 they cease to be relevant, 
the reciprocal quantity is more pertinent leading to optical photon simulation 
times that are effectively zero compared to the rest of the simulation. 
In addition CPU memory requirements are drastically reduced as photons 
are generated and propagated entirely on the GPU with only detected photons 
being copied to the CPU. 

\begin{table}[h]
\caption{Comparison of photon propagation times in seconds obtained with Macbook Pro(2013) NVIDIA GeForce GT 750M, 2048MB, 384 cores.
The first column lists photon counts and geometries. Rainbow geometry is a spherical drop of water. Opticks interop mode
uses OpenGL buffers to allow visualizations is approximately a factor of 7 slower that Opticks compute mode which uses
pure OptiX buffers. Perfectly identical results verified by digest are achieved for interop and compute modes. Good statistical 
agreement is achieved between the Geant4 and Opticks simulations. 
} 
\begin{center}
\begin{tabular}{llll}
\br
Geometry & Geant4 10.2 & Opticks Interop & Opticks Compute \\
\mr
1M Rainbow (S polarized) &  56 & 1.62 & 0.28 \\
1M Rainbow (P polarized) &  58 & 1.71 & 0.25 \\
0.5M PMT in Mineral Oil  &  41 & 0.81 & 0.15 \\
\br
\end{tabular}
\end{center}
\end{table}

Expanding validation to full detector geometries requires the types of geometry that 
Opticks can analytically intersect with to be increased.
Exploratory development of an OptiX CSG boolean implementation is ongoing\cite{CSG}.
Adaption of the VecGeom solid CUDA implementations to work within the OptiX context 
is another possibility for investigation.

%\begin{itemize}
%SKIP: NOT MY PURVIEW:\item acceleration structure fully decoupled from geometry description 
%\item performance comparison
%\item performance factors so large they become irrelevant, its the reciprocal are interested in 
%\item principal contribution : context translation (geometry, materials and surfaces) from G4 into a GPU appropriate form
%      enabling optical physics simulation to benefit from state-of-the art GPU ray tracing from NVIDIA OptiX
%\item boolean CSG on GPU
%\item G4DAE integrated with Geant4
%\end{itemize}


\section*{References}
\begin{thebibliography}{9}

%1
\bibitem{newton} 
Newton I 
1704 
Opticks: or, a treatise of the reflections, refractions, inflexions and colours of light.
{\it Printers to Royal Society, London} 

%2
\bibitem{opticksURL} 
Opticks URL {\tt https://bitbucket.org/simoncblyth/opticks/}

%3
\bibitem{g4A} 
Agostinelli S, Allison J, Amako K, Apostolakis J, Araujo H, Arce P, et al. 
2003  
Geant4--a simulation toolkit 
{\it Nucl Instrum Methods Phys Res} A {\bf 506} pp 250-–303 

%4
\bibitem{g4B} 
Allison J, Amako K, Apostolakis J, Araujo H, Dubois P, Asai M, et al. 
2006 
Geant4 developments and applications 
{\it IEEE Trans Nucl Sci} {\bf 53} pp 270--8

%5
\bibitem{g4C} 
Allison J, Amako K, Apostolakis J, Arce P, Asai M, Aso T, et al. 
2016 
Recent developments in Geant4 
{\it Nucl Instrum Methods Phys Res} A {\bf 835} pp 186--225

%6
\bibitem{optixPaper} 
Parker S, Bigler J, Dietrich A, Friedrich H, Hoberock J, Luebke D, McAllister D, McGuire M, Morley K, Robison A and Stich M 
2010 
OptiX: a general purpose ray tracing engine
{\it ACM Trans. Graph. : Conf. Series} {\bf 29} p 66 

%7
\bibitem{optixSite} 
NVIDIA{\textregistered} OptiX\texttrademark~ webpage {\tt https://developer.nvidia.com/optix}

%\bibitem{optixGuide}
%OptiX Programming Guide 3.0.0 available from {\tt https://developer.nvidia.com/optix}
%{\tt http://developer.download.nvidia.com/assets/tools/files/optix/3.0.0/NVIDIA-OptiX-SDK-3.0.0-OptiX\_Programming\_Guide\_3.0.0.pdf}


%8
\bibitem{dyb}
An F, et al.
2016
The detector system of the Daya Bay reactor neutrino experiment
{\it Nucl Instrum Methods} A {\bf 811} pp 133--161

%9
\bibitem{juno}
An F et al.  
2016
Neutrino physics with JUNO
{\it J Phys G} {\bf 43} 030401

%10
\bibitem{megakernels}
Laine S, Karras T and Aila T
2013
Megakernels considered harmful: wavefront path tracing on GPUs
{\it Proceedings of the 5th High-Performance Graphics Conference} pp 137--143

%11
\bibitem{understanding}
Aila T and Laine S 
2009
Understanding the efficiency of ray traversal on GPUs
{\it Proceedings of the Conference on High Performance Graphics} pp 145--149

%12
\bibitem{understandingAddendum}
Aila T, Laine S and Karras T
2012
Understanding the Efficiency of Ray Tracing on GPUs – Kepler \& Fermi addendum. 
{\it NVIDIA Technical Report NVR–2012–02}
% https://mediatech.aalto.fi/~samuli/publications/aila2012tr1_paper.pdf
% ray tracing is still, even with incoherent rays and more complex scenes, 
% almost entirely limited by the available FLOPS

%13
\bibitem{chromaURL} 
Chroma URL {\tt http://chroma.bitbucket.org}

%14
\bibitem{chromaB} 
Seibert S and LaTorre A 
2011 
Fast optical monte carlo simulation with surface-based geometries using Chroma {\tt http://chroma.bitbucket.org/\_downloads/chroma.pdf}

%15
\bibitem{chromaFork} 
Fork of Chroma {\tt http://bitbucket.org/simoncblyth/chroma}

%16
\bibitem{GeantV}
Amadio G, Apostolakis J, Bandieramonte M, Bhattacharyya A, Bianchini C, Brun R, Canal P, et al.
2015
The GeantV project : preparing the future of simulation 
{\it J. Phys.: Conf. Series} {\bf 664} 072006

%17
\bibitem{VecGeom}
Apostolakis J, Bandieramonte M, Bitzes G, Brun R, Canal P, Carminati F, et al. 
2015
Towards a high performance geometry library for particle-detector simulations
{\it J. Phys.: Conf. Series} {\bf 608} 012023
%http://iopscience.iop.org/article/10.1088/1742-6596/608/1/012023/pdf

%18
\bibitem{sbvh}
Stich M, Friedrich H and Dietrich A 
2009
Spatial Splits in Bounding Volume Hierarchies


%\bibitem{colladaURL}
%COLLADA URL {\tt https://www.khronos.org/collada/}

%19
\bibitem{g4daeURL} 
G4DAE URL {\tt https://bitbucket.org/simoncblyth/g4dae/}

%20
\bibitem{AssimpFork}
Fork of Assimp supporting G4DAE extra optical properties {\tt https://github.com/simoncblyth/assimp}

%21
\bibitem{Assimp}
Assimp URL {\tt http://www.assimp.org}

%\bibitem{OpenMesh}
%OpenMesh URL {\tt https://www.openmesh.org}

%22
\bibitem{NPY}
Kern R
2007
A Simple File Format for NumPy Arrays
{\tt https://docs.scipy.org/doc/numpy/neps/npy-format.html}

%23
\bibitem{ipython}
IPython URL {\tt https://ipython.org}

%24
\bibitem{numpy}
Van der Walt S, Colbert S, Varoquaux G 
2011 
The NumPy array: a structure for efficient numerical computation
{\it Comput. Sci. Eng.} {\bf 13} pp 22--30

%\bibitem{cudaPaper}
%Nickolls J, Buck I, Garland M and Skadron K 
%2008
%Scalable Parallel Programming with CUDA
%{\it ACM Queue} {\bf 6} pp 40--53
%
%\bibitem{cudaURL}
%CUDA URL {\tt http://www.nvidia.com/object/cuda\_home\_new.html}

%25
\bibitem{thrust}
Bell N and Hoberock J 
2011
{\it Thrust: a Productivity-Oriented Library for CUDA}
(GPU Computing Gems Jade Edition) ed W W Hwu, Chapter 26   

%26
\bibitem{thrustURL} 
Thrust URL {\tt https://developer.nvidia.com/thrust}

%27
\bibitem{curandURL}
cuRAND URL {\tt http://docs.nvidia.com/cuda/curand/index.html}


%
%\bibitem{opengl}
%Shreiner D, Sellers G, Kessenich J, Licea-Kane B 
%2013
%{\it OpenGL Programming Guide: The Official Guide to Learning OpenGL, Version 4.3}
%

%28
\bibitem{ImGui}
ImGui URL {\tt https://github.com/ocornut/imgui}

%29
\bibitem{CSG}
Single Hit CSG
{\tt http://xrt.wikidot.com/doc:csg}

%\bibitem{junoFastSim}
%Lin T, Deng Z, Li W, Cao G, You Z and Li X
%2016
%Fast muon simulation in the JUNO central detector
%{\it Chin. Phys. C} {\bf 40} 8 086201
%
%\bibitem{IceCubeGPU}
%Chirkin D
%2013
%Photon tracking with GPUs in IceCube
%{\it Nucl Instrum Methods Phys Res} A {\bf 725} pp 141--143
%
% https://arxiv.org/abs/astro-ph/0702108
% https://arxiv.org/pdf/astro-ph/0702108v2.pdf

\end{thebibliography}

\end{document}


