Index: bitten/admin.py
===================================================================
--- bitten/admin.py	(revision 561)
+++ bitten/admin.py	(working copy)
@@ -235,6 +235,22 @@
             config.delete(db=db)
         db.commit()
 
+
+    def _resolve_recipe(self, recipe_xml , authname ):
+        """ CAUTION : this is duplicated in master.py """
+        if recipe_xml.startswith('source:'):
+            self.log.info("_resolve_recipe using repopath as source of the recipe %s " % recipe_xml )
+            repos = self.env.get_repository(authname)
+            recipe_path = recipe_xml[7:]
+            try: 
+                node = repos.get_node( recipe_path )
+                recipe_xml = node.get_content().read()
+                self.log.debug("_resolve_recipe got recipe_xml %s " % recipe_xml )
+            except (AssertionError, TracError), e:
+                raise TracError(unicode(e), 'Invalid Repository Path')
+        return recipe_xml
+
+
     def _update_config(self, req, config):
         req.perm.assert_permission('BUILD_MODIFY')
 
@@ -259,8 +275,9 @@
             except TracError, e:
                 raise TracError(unicode(e), 'Invalid Oldest Revision')
 
-        recipe_xml = req.args.get('recipe', '')
-        if recipe_xml:
+        recipe_arg = req.args.get('recipe', '')
+        if recipe_arg:
+            recipe_xml = self._resolve_recipe(recipe_arg, req.authname )
             try:
                 Recipe(xmlio.parse(recipe_xml)).validate()
             except xmlio.ParseError, e:
@@ -271,7 +288,7 @@
 
         config.name = name
         config.path = repos.normalize_path(path)
-        config.recipe = recipe_xml
+        config.recipe = recipe_arg
         config.min_rev = req.args.get('min_rev')
         config.max_rev = req.args.get('max_rev')
         config.label = req.args.get('label', config.name)
Index: bitten/master.py
===================================================================
--- bitten/master.py	(revision 561)
+++ bitten/master.py	(working copy)
@@ -160,6 +160,24 @@
         req.write('')
         raise RequestDone
 
+
+    def _resolve_recipe(self, recipe_xml , authname ):
+        """ minor fix to allow entry of source:/trunk/etc/recipe.xml paths rather than the actual xml 
+             CAUTION : this code is duplicated in master.py and admin.py 
+        """ 
+        if recipe_xml.startswith('source:'):
+            self.log.info("_resolve_recipe using repopath as source of the recipe %s " % recipe_xml )
+            repos = self.env.get_repository(authname)
+            recipe_path = recipe_xml[7:]
+            try:
+                node = repos.get_node( recipe_path )
+                recipe_xml = node.get_content().read()
+                self.log.debug("_resolve_recipe got recipe_xml %s " % recipe_xml )
+            except (AssertionError, TracError), e:
+                raise TracError(unicode(e), 'Invalid Repository Path')
+        return recipe_xml
+                            
+                                            
     def _process_build_initiation(self, req, config, build):
         self.log.info('Build slave %r initiated build %d', build.slave,
                       build.id)
@@ -169,7 +187,8 @@
         for listener in BuildSystem(self.env).listeners:
             listener.build_started(build)
 
-        xml = xmlio.parse(config.recipe)
+        recipe_xml = self._resolve_recipe(config.recipe, req.authname)
+        xml = xmlio.parse(recipe_xml)
         xml.attr['path'] = config.path
         xml.attr['revision'] = build.rev
         xml.attr['config'] = config.name
@@ -198,14 +217,16 @@
         stepname = elem.attr['step']
 	
         # make sure it's the right slave.
-        if build.status != Build.IN_PROGRESS or build.slave_info.get(Build.IP_ADDRESS) != req.remote_addr:
-            raise HTTPForbidden('Build %s has been invalidated for host %s.' % (build.id, req.remote_addr))
-
+        if build.status != Build.IN_PROGRESS:
+            raise HTTPForbidden('Build %s has been invalidated for host %s. inconsistent IP no longer 403s (#282) ' % (build.id, req.remote_addr))
+        if build.slave_info.get(Build.IP_ADDRESS) != req.remote_addr:
+            self.log.error('The slave REMOTE_ADDR has changed during the build prior IP %s current IP %s (#282)  ', build.slave_info.get(Build.IP_ADDRESS),  req.remote_addr )
         step = BuildStep.fetch(self.env, build=build.id, name=stepname)
         if step:
             raise HTTPConflict('Build step already exists')
 
-        recipe = Recipe(xmlio.parse(config.recipe))
+        recipe_xml = self._resolve_recipe(config.recipe, req.authname)
+        recipe = Recipe(xmlio.parse(recipe_xml))
         index = None
         current_step = None
         for num, recipe_step in enumerate(recipe):
Index: bitten/build/pythontools.py
===================================================================
--- bitten/build/pythontools.py	(revision 561)
+++ bitten/build/pythontools.py	(working copy)
@@ -438,7 +438,7 @@
             for child in xmlio.parse(fileobj).children():
                 test = xmlio.Element('test')
                 for name, value in child.attr.items():
-                    if name == 'file':
+                    if name == 'realfile':
                         value = os.path.realpath(value)
                         if value.startswith(ctxt.basedir):
                             value = value[len(ctxt.basedir) + 1:]
Index: bitten/web_ui.py
===================================================================
--- bitten/web_ui.py	(revision 561)
+++ bitten/web_ui.py	(working copy)
@@ -27,6 +27,7 @@
                             add_link, add_stylesheet, add_ctxtnav, \
                             prevnext_nav, add_script
 from trac.wiki import wiki_to_html, wiki_to_oneliner
+from trac.versioncontrol.api import NoSuchNode
 from bitten.api import ILogFormatter, IReportChartGenerator, IReportSummarizer
 from bitten.model import BuildConfig, TargetPlatform, Build, BuildStep, \
                          BuildLog, Report
@@ -383,7 +384,7 @@
         add_link(req, 'up', req.href.build(build.config),
                  'Build Configuration')
         status2title = {Build.SUCCESS: 'Success', Build.FAILURE: 'Failure',
-                        Build.IN_PROGRESS: 'In Progress'}
+                        Build.IN_PROGRESS: 'In Progress', Build.PENDING:'Pending' }
         data = {'title': 'Build %s - %s' % (build_id,
                                             status2title[build.status]),
                 'page_mode': 'view_build',
@@ -582,30 +583,57 @@
 
     _fileref_re = re.compile('(?P<path>[\w.-]+(?:/[\w.-]+)+)(?P<line>(:\d+))?')
 
-    def get_formatter(self, req, build):
+    def get_formatter(self, req, build, **kw):
         """Return the log message formatter function."""
         config = BuildConfig.fetch(self.env, name=build.config)
+        self.log.debug("get_formatter config.path %s build.rev %s " % (config.path,build.rev) )
         repos = self.env.get_repository(req.authname)
         href = req.href.browser
-        cache = {}
+        repocache = {}
+        filecache = {}
 
+        def _pathsearch( filepath ):
+            """ grow the path backwards from the leaf """
+            parts = filepath.split('/')
+            parts.reverse()         
+            path = None        
+            for part in parts:
+                path = path and posixpath.join( part , path ) or part
+                repopath = posixpath.join(config.path, path)
+                self.log.debug("try repopath %s " %  repopath)
+                if repopath not in repocache:
+                    try: 
+                        repos.get_node( repopath , build.rev)
+                        repocache[repopath] = True
+                        self.log.debug("non-cache repopath %s %s " %  (repopath,repocache[repopath]) )
+                        return repopath
+                    except NoSuchNode, e:
+                        repocache[repopath] = False
+                        self.log.debug("non-cache repopath %s %s " %  (repopath,repocache[repopath]) )
+                    except:
+                        self.log.error("other exception ")
+                else:
+                    self.log.debug("from-cache repopath %s %s " %  (repopath,repocache[repopath]) ) 
+            return None
+
+
+
         def _replace(m):
+            self.log.debug("_replace %s  " % (m.groupdict())  )
             filepath = posixpath.normpath(m.group('path').replace('\\', '/'))
-            if not cache.get(filepath) is True:
-                parts = filepath.split('/')
-                path = ''
-                for part in parts:
-                    path = posixpath.join(path, part)
-                    if path not in cache:
-                        try:
-                            repos.get_node(posixpath.join(config.path, path),
-                                           build.rev)
-                            cache[path] = True
-                        except TracError:
-                            cache[path] = False
-                    if cache[path] is False:
-                        return m.group(0)
-            link = href(config.path, filepath)
+            repopath = None
+            
+            if filecache.has_key(filepath) :
+                repopath = filecache[filepath]
+            else:
+                repopath = filecache[filepath] = _pathsearch( filepath )   
+           
+            if repopath is None:
+                self.log.debug("miss filepath %s " % (filepath) )
+                return m.group(0)
+                    
+            link = href( repopath , **kw )
+            self.log.debug("hit filepath %s " %  ( filepath ) )
             if m.group('line'):
                 link += '#L' + m.group('line')[1:]
             return Markup(tag.a(m.group(0), href=link))
@@ -613,14 +641,16 @@
         def _formatter(step, type, level, message):
             buf = []
             offset = 0
+            self.log.debug("bitten formatter start")
             for mo in self._fileref_re.finditer(message):
                 start, end = mo.span()
+                #self.log.debug("found %s " % message[offset:start])
                 if start > offset:
                     buf.append(message[offset:start])
                 buf.append(_replace(mo))
                 offset = end
             if offset < len(message):
                 buf.append(message[offset:])
-            return Markup("").join(buf)
+            return Markup("".join(buf))   ## we want the links to work ... not be escaped 
 
         return _formatter
Index: bitten/slave.py
===================================================================
--- bitten/slave.py	(revision 561)
+++ bitten/slave.py	(working copy)
@@ -115,6 +115,9 @@
         self.poll_interval = poll_interval
         self.dump_reports = dump_reports
 
+        username = username or self.config['slv.username']
+        password = password or self.config['slv.password']
+
         if not self.local:
             self.opener = urllib2.build_opener(SaneHTTPErrorProcessor)
             password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
@@ -145,6 +148,8 @@
             return os.EX_OK
 
         while True:
+            socket.setdefaulttimeout(15)
+            #log.info('Setting socket.defaulttimeout : %s ' , socket.getdefaulttimeout() ) 
             try:
                 try:
                     job_done = self._create_build()
Index: bitten/report/testing.py
===================================================================
--- bitten/report/testing.py	(revision 561)
+++ bitten/report/testing.py	(working copy)
@@ -35,9 +35,9 @@
  LEFT OUTER JOIN bitten_report AS report ON (report.build=build.id)
  LEFT OUTER JOIN bitten_report_item AS item_status
   ON (item_status.report=report.id AND item_status.name='status')
-WHERE build.config=%s AND report.category='test'
+WHERE build.config=%s AND report.category='test' AND build.rev > %s
 GROUP BY build.rev_time, build.rev, build.platform, item_status.value
-ORDER BY build.rev_time, build.platform""", (config.name,))
+ORDER BY build.rev_time, build.platform""", (config.name,config.min_rev))
 
         prev_rev = None
         prev_platform, platform_total = None, 0
Index: bitten/queue.py
===================================================================
--- bitten/queue.py	(revision 561)
+++ bitten/queue.py	(working copy)
@@ -31,8 +31,53 @@
 __docformat__ = 'restructuredtext en'
 
 log = logging.getLogger('bitten.queue')
+non_alpnumspc = re.compile(r'[^a-zA-Z0-9_ ]+')
 
+def changeset_location(chgset):
+    """ common prefix of all the new paths in the changeset """
+    paths = []
+    for path, kind, change, base_path, base_rev in chgset.get_changes():
+        paths.append(path)
+    return commonprefix( paths )
 
+def commonprefix(paths):
+    import os
+    return '/'.join(os.path.commonprefix([p.split('/') for p in paths]))
+
+def is_contained( loc , paths ):
+    """
+        is_contained( "a/b"     ,     ["a/b/c" , "x/y/z" ] ) == False
+        is_contained( "a/b/c"   ,     ["a/b/c" , "x/y/z" ] ) == True
+        is_contained( "a/b/cc" ,      ["a/b/c" , "x/y/z" ] ) == False
+        is_contained( "a/b/c/d" ,     ["a/b/c" , "x/y/z" ] ) == True
+        is_contained( "x/y/z" ,       ["a/b/c" , "x/y/z" ] ) == True
+        is_contained( "x/y/z/z" ,     ["a/b/c" , "x/y/z" ] ) == True
+         
+    """    
+    return len([ p for p in paths if commonprefix( [ p , loc ] ) == p ]) > 0
+
+def include_( path , include="" ):
+    return include == "" or  is_contained( path , include.split(",") )
+    
+def exclude_( path , exclude="" ):
+    return exclude != "" and is_contained( path , exclude.split(",") )
+
+def mxclude_( message , exclude="" ):
+    words = message.split()
+    return exclude != "" and  len( filter(lambda skip:skip in words, exclude.split(",")) ) > 0  
+
+
+def accept_( chgset , include , exclude , exclude_words ):
+    path = changeset_location( chgset )
+    msg = non_alpnumspc.sub('',chgset.message) 
+    incl = include_( path , include )
+    excl = exclude_( path , exclude )
+    mxcl = mxclude_( msg , exclude_words ) 
+    acpt = incl and not(excl) and not(mxcl)
+    msg = "accept_ %s incl:%s [%s] excl:%s mxcl:%s [%s] [%s] [%s] " % ( acpt , incl , include , excl , mxcl , exclude , exclude_words , msg  )
+    return acpt, msg
+    
+
 def collect_changes(repos, config, db=None):
     """Collect all changes for a build configuration that either have already
     been built, or still need to be built.
@@ -217,8 +262,18 @@
         db = self.env.get_db_cnx()
         builds = []
 
+        # trac ini access for include/exclude paths for the config 
+        cfg = self.env.config['bitten']
+        
         for config in BuildConfig.select(self.env, db=db):
             platforms = []
+    
+            exclude_words = cfg.get('%s.exclude_words' % config.name )
+            exclude_paths = cfg.get('%s.exclude_paths' % config.name )
+            include_paths = cfg.get('%s.include_paths' % config.name )
+            self.log.info('populate ... config: %s config.path: %s exclude: %s include: %s exclude_words:%s ', config.name , config.path, exclude_paths , include_paths, exclude_words )
+                        
+
             for platform, rev, build in collect_changes(repos, config, db):
 
                 if not self.build_all and platform.id in platforms:
@@ -231,6 +286,23 @@
                 platforms.append(platform.id)
 
                 if build is None:
+                
+                    #
+                    #  Use location of the changeset for include/exclude filtering
+                    #  for NEW BUILDS ONLY
+                    #    ... collect_changes is called from multiple places including web_ui, so 
+                    #   cannot put this in there, as want to just filter new builds without making
+                    #   orphans of old builds
+                    #
+                    
+                    chgset = repos.get_changeset(rev)
+                    ok, msg = accept_( chgset , include_paths , exclude_paths, exclude_words )
+                    if ok:
+                        self.log.info('accepting Enqueing chgset %s .. %s ', rev, msg)
+                    else:
+                        self.log.info('rejecting Enqueing chgset %s .. %s ', rev, msg)
+                        continue
+                
                     self.log.info('Enqueuing build of configuration "%s" at '
                                   'revision [%s] on %s', config.name, rev,
                                   platform.name)
@@ -292,10 +364,12 @@
         # Ignore pending builds for deactived build configs
         config = BuildConfig.fetch(self.env, build.config)
         if not config.active:
+            plat = TargetPlatform.fetch(self.env, build.platform)
+            platname = plat and plat.name or "ERROR-NO-PLATFORM"  
             log.info('Dropping build of configuration "%s" at '
                      'revision [%s] on "%s" because the configuration is '
                      'deactivated', config.name, build.rev,
-                     TargetPlatform.fetch(self.env, build.platform).name)
+                      platname )
             return True
 
         # Stay within the revision limits of the build config
@@ -305,10 +379,13 @@
                                                     build.rev)):
             # This minimum and/or maximum revision has changed since
             # this build was enqueued, so drop it
+
+            plat = TargetPlatform.fetch(self.env, build.platform)
+            platname = plat and plat.name or "ERROR-NO-PLATFORM"  
             log.info('Dropping build of configuration "%s" at revision [%s] on '
                      '"%s" because it is outside of the revision range of the '
                      'configuration', config.name, build.rev,
-                     TargetPlatform.fetch(self.env, build.platform).name)
+                     platname)
             return True
 
         return False
